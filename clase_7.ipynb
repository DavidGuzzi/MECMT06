{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadstat as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lfp</th>\n",
       "      <th>whrs</th>\n",
       "      <th>kl6</th>\n",
       "      <th>k618</th>\n",
       "      <th>wa</th>\n",
       "      <th>we</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1610</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1568</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lfp  whrs  kl6  k618  wa  we\n",
       "0    1  1610    1     0  32  12\n",
       "1    1  1656    0     2  30  12\n",
       "2    1  1980    1     3  35  12\n",
       "3    1   456    0     3  34  12\n",
       "4    1  1568    1     2  31  14"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\DiTella\\MEC\\Materias\\2024 3T\\[MT06] Microeconometría I\\Clases\\Stata\\Archivos Stata-20250107\\laborsub.dta\"\n",
    "\n",
    "df, meta = st.read_dta(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   lfp     250 non-null    int64\n",
      " 1   whrs    250 non-null    int64\n",
      " 2   kl6     250 non-null    int64\n",
      " 3   k618    250 non-null    int64\n",
      " 4   wa      250 non-null    int64\n",
      " 5   we      250 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 11.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 if woman worked in 1975',\n",
       " \"Wife's hours of work\",\n",
       " '# of children younger than 6',\n",
       " '# of children between 6 and 18',\n",
       " \"Wife's age\",\n",
       " \"Wife's educational attainment\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.column_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lfp\n",
       "1    150\n",
       "0    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lfp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>whrs</th>\n",
       "      <td>250.0</td>\n",
       "      <td>799.84</td>\n",
       "      <td>915.60348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.5</td>\n",
       "      <td>1599.75</td>\n",
       "      <td>4950.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count    mean        std  min  25%    50%      75%     max\n",
       "whrs  250.0  799.84  915.60348  0.0  0.0  406.5  1599.75  4950.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['whrs']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   whrs   R-squared:                       0.072\n",
      "Model:                            OLS   Adj. R-squared:                  0.046\n",
      "Method:                 Least Squares   F-statistic:                     2.802\n",
      "Date:                Thu, 20 Feb 2025   Prob (F-statistic):             0.0281\n",
      "Time:                        23:26:34   Log-Likelihood:                -1214.6\n",
      "No. Observations:                 150   AIC:                             2439.\n",
      "Df Residuals:                     145   BIC:                             2454.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1629.8168    615.130      2.650      0.009     414.037    2845.597\n",
      "kl6         -421.4822    167.973     -2.509      0.013    -753.475     -89.490\n",
      "k618        -104.4571     54.186     -1.928      0.056    -211.554       2.640\n",
      "wa            -4.7849      9.691     -0.494      0.622     -23.938      14.368\n",
      "we             9.3532     31.238      0.299      0.765     -52.387      71.094\n",
      "==============================================================================\n",
      "Omnibus:                       28.314   Durbin-Watson:                   2.066\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               53.578\n",
      "Skew:                           0.864   Prob(JB):                     2.32e-12\n",
      "Kurtosis:                       5.364   Cond. No.                         425.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#¿Qué sucede si queremos estimar una función de oferta de trabajo?\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Filtrar datos donde whrs > 0\n",
    "df_filtered = df[df[\"whrs\"] > 0]\n",
    "\n",
    "# Definir variables dependiente (Y) e independientes (X)\n",
    "y = df_filtered[\"whrs\"]\n",
    "X = df_filtered[[\"kl6\", \"k618\", \"wa\", \"we\"]]\n",
    "\n",
    "# Agregar constante para la intersección (equivalente a _cons en Stata)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Ajustar el modelo\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Mostrar resultados\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Tobit' from 'statsmodels.discrete.count_model' (c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\discrete\\count_model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiscrete\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcount_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tobit\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Definir variables dependiente (Y) e independientes (X)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhrs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Tobit' from 'statsmodels.discrete.count_model' (c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\discrete\\count_model.py)"
     ]
    }
   ],
   "source": [
    "from statsmodels.discrete.count_model import Tobit\n",
    "\n",
    "# Definir variables dependiente (Y) e independientes (X)\n",
    "y = df[\"whrs\"]\n",
    "X = df[[\"kl6\", \"k618\", \"wa\", \"we\"]]\n",
    "\n",
    "# Agregar constante para la intersección (equivalente a _cons en Stata)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Ajustar el modelo Tobit con censura inferior en 0\n",
    "model = Tobit(y, X).fit(censor_lower=0)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:592: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x1) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes estimados: [-5200401.23618509  1717029.03177521   313985.12206049    94771.03642374\n",
      "    44524.92114298]\n",
      "Sigma estimado: 510055.98735519126\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Definir variables dependiente (Y) e independientes (X)\n",
    "y = df[\"whrs\"]\n",
    "X = df[[\"kl6\", \"k618\", \"wa\", \"we\"]]\n",
    "\n",
    "# Agregar constante\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Función de log-verosimilitud del modelo Tobit (censura inferior en 0)\n",
    "def tobit_loglik(params, y, X):\n",
    "    beta = params[:-1]  # Coeficientes de regresión\n",
    "    sigma = params[-1]  # Desviación estándar del error\n",
    "    \n",
    "    if sigma <= 0:\n",
    "        return np.inf  # Evitar valores no válidos\n",
    "    \n",
    "    xb = X @ beta  # Producto matricial X * beta\n",
    "    uncensored = (y > 0)\n",
    "    \n",
    "    # Parte no censurada: Log-verosimilitud de la normal\n",
    "    ll_uncensored = -0.5 * np.log(2 * np.pi) - np.log(sigma) - (y - xb) ** 2 / (2 * sigma**2)\n",
    "    \n",
    "    # Parte censurada: Probabilidad acumulada de la normal (usando scipy.stats.norm)\n",
    "    ll_censored = np.log(np.maximum(norm.cdf(xb / sigma), 1e-10))  # Evita log(0)\n",
    "    \n",
    "    # Combinar log-verosimilitudes\n",
    "    loglik = np.where(uncensored, ll_uncensored, ll_censored)\n",
    "    \n",
    "    return -np.sum(loglik)  # Maximizar la verosimilitud minimizando la función de pérdida\n",
    "\n",
    "# Estimación de parámetros iniciales\n",
    "init_params = np.append(np.zeros(X.shape[1]), 1)  # Coeficientes iniciales + sigma\n",
    "\n",
    "# Optimización numérica\n",
    "res = minimize(tobit_loglik, init_params, args=(y, X), method=\"BFGS\")\n",
    "\n",
    "# Resultados\n",
    "beta_est = res.x[:-1]  # Coeficientes estimados\n",
    "sigma_est = res.x[-1]  # Estimación de sigma\n",
    "\n",
    "print(\"Coeficientes estimados:\", beta_est)\n",
    "print(\"Sigma estimado:\", sigma_est)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats\n",
    "from scipy.special import log_ndtr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def split_left_right_censored(x, y, cens):\n",
    "    counts = cens.value_counts()\n",
    "    if -1 not in counts and 1 not in counts:\n",
    "        warnings.warn(\"No censored observations; use regression methods for uncensored data\")\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for value in [-1, 0, 1]:\n",
    "        if value in counts:\n",
    "            split = cens == value\n",
    "            y_split = np.squeeze(y[split].values)\n",
    "            x_split = x[split].values\n",
    "\n",
    "        else:\n",
    "            y_split, x_split = None, None\n",
    "        xs.append(x_split)\n",
    "        ys.append(y_split)\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "def tobit_neg_log_likelihood(xs, ys, params):\n",
    "    x_left, x_mid, x_right = xs\n",
    "    y_left, y_mid, y_right = ys\n",
    "\n",
    "    b = params[:-1]\n",
    "    # s = math.exp(params[-1])\n",
    "    s = params[-1]\n",
    "\n",
    "    to_cat = []\n",
    "\n",
    "    cens = False\n",
    "    if y_left is not None:\n",
    "        cens = True\n",
    "        left = (y_left - np.dot(x_left, b))\n",
    "        to_cat.append(left)\n",
    "    if y_right is not None:\n",
    "        cens = True\n",
    "        right = (np.dot(x_right, b) - y_right)\n",
    "        to_cat.append(right)\n",
    "    if cens:\n",
    "        concat_stats = np.concatenate(to_cat, axis=0) / s\n",
    "        log_cum_norm = scipy.stats.norm.logcdf(concat_stats)  # log_ndtr(concat_stats)\n",
    "        cens_sum = log_cum_norm.sum()\n",
    "    else:\n",
    "        cens_sum = 0\n",
    "\n",
    "    if y_mid is not None:\n",
    "        mid_stats = (y_mid - np.dot(x_mid, b)) / s\n",
    "        mid = scipy.stats.norm.logpdf(mid_stats) - math.log(max(np.finfo('float').resolution, s))\n",
    "        mid_sum = mid.sum()\n",
    "    else:\n",
    "        mid_sum = 0\n",
    "\n",
    "    loglik = cens_sum + mid_sum\n",
    "\n",
    "    return - loglik\n",
    "\n",
    "\n",
    "def tobit_neg_log_likelihood_der(xs, ys, params):\n",
    "    x_left, x_mid, x_right = xs\n",
    "    y_left, y_mid, y_right = ys\n",
    "\n",
    "    b = params[:-1]\n",
    "    # s = math.exp(params[-1]) # in censReg, not using chain rule as below; they optimize in terms of log(s)\n",
    "    s = params[-1]\n",
    "\n",
    "    beta_jac = np.zeros(len(b))\n",
    "    sigma_jac = 0\n",
    "\n",
    "    if y_left is not None:\n",
    "        left_stats = (y_left - np.dot(x_left, b)) / s\n",
    "        l_pdf = scipy.stats.norm.logpdf(left_stats)\n",
    "        l_cdf = log_ndtr(left_stats)\n",
    "        left_frac = np.exp(l_pdf - l_cdf)\n",
    "        beta_left = np.dot(left_frac, x_left / s)\n",
    "        beta_jac -= beta_left\n",
    "\n",
    "        left_sigma = np.dot(left_frac, left_stats)\n",
    "        sigma_jac -= left_sigma\n",
    "\n",
    "    if y_right is not None:\n",
    "        right_stats = (np.dot(x_right, b) - y_right) / s\n",
    "        r_pdf = scipy.stats.norm.logpdf(right_stats)\n",
    "        r_cdf = log_ndtr(right_stats)\n",
    "        right_frac = np.exp(r_pdf - r_cdf)\n",
    "        beta_right = np.dot(right_frac, x_right / s)\n",
    "        beta_jac += beta_right\n",
    "\n",
    "        right_sigma = np.dot(right_frac, right_stats)\n",
    "        sigma_jac -= right_sigma\n",
    "\n",
    "    if y_mid is not None:\n",
    "        mid_stats = (y_mid - np.dot(x_mid, b)) / s\n",
    "        beta_mid = np.dot(mid_stats, x_mid / s)\n",
    "        beta_jac += beta_mid\n",
    "\n",
    "        mid_sigma = (np.square(mid_stats) - 1).sum()\n",
    "        sigma_jac += mid_sigma\n",
    "\n",
    "    combo_jac = np.append(beta_jac, sigma_jac / s)  # by chain rule, since the expression above is dloglik/dlogsigma\n",
    "\n",
    "    return -combo_jac\n",
    "\n",
    "\n",
    "class TobitModel:\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.ols_coef_ = None\n",
    "        self.ols_intercept = None\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.sigma_ = None\n",
    "\n",
    "    def fit(self, x, y, cens, verbose=False):\n",
    "        \"\"\"\n",
    "        Fit a maximum-likelihood Tobit regression\n",
    "        :param x: Pandas DataFrame (n_samples, n_features): Data\n",
    "        :param y: Pandas Series (n_samples,): Target\n",
    "        :param cens: Pandas Series (n_samples,): -1 indicates left-censored samples, 0 for uncensored, 1 for right-censored\n",
    "        :param verbose: boolean, show info from minimization\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x_copy = x.copy()\n",
    "        if self.fit_intercept:\n",
    "            x_copy.insert(0, 'intercept', 1.0)\n",
    "        else:\n",
    "            x_copy.scale(with_mean=True, with_std=False, copy=False)\n",
    "        init_reg = LinearRegression(fit_intercept=False).fit(x_copy, y)\n",
    "        b0 = init_reg.coef_\n",
    "        y_pred = init_reg.predict(x_copy)\n",
    "        resid = y - y_pred\n",
    "        resid_var = np.var(resid)\n",
    "        s0 = np.sqrt(resid_var)\n",
    "        params0 = np.append(b0, s0)\n",
    "        xs, ys = split_left_right_censored(x_copy, y, cens)\n",
    "\n",
    "        result = minimize(lambda params: tobit_neg_log_likelihood(xs, ys, params), params0, method='BFGS',\n",
    "                          jac=lambda params: tobit_neg_log_likelihood_der(xs, ys, params), options={'disp': verbose})\n",
    "        if verbose:\n",
    "            print(result)\n",
    "        self.ols_coef_ = b0[1:]\n",
    "        self.ols_intercept = b0[0]\n",
    "        if self.fit_intercept:\n",
    "            self.intercept_ = result.x[1]\n",
    "            self.coef_ = result.x[1:-1]\n",
    "        else:\n",
    "            self.coef_ = result.x[:-1]\n",
    "            self.intercept_ = 0\n",
    "        self.sigma_ = result.x[-1]\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.intercept_ + np.dot(x, self.coef_)\n",
    "\n",
    "    def score(self, x, y, scoring_function=mean_absolute_error):\n",
    "        y_pred = np.dot(x, self.coef_)\n",
    "        return scoring_function(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 294.44827939, -827.78090417, -140.01430074,  -24.97854148,\n",
       "        103.69518044])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"whrs\"]\n",
    "X = df[[\"kl6\", \"k618\", \"wa\", \"we\"]]\n",
    "X = sm.add_constant(X)\n",
    "df['cens'] = np.where(df['whrs'] == 0, -1, 0)\n",
    "cens = df['cens']\n",
    "tr = TobitModel()\n",
    "tr = tr.fit(X, y, cens, verbose=False)\n",
    "tr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_7068\\1321454343.py:16: UserWarning: No censored observations; use regression methods for uncensored data\n",
      "  warnings.warn(\"No censored observations; use regression methods for uncensored data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 470.02964199, -462.12329817,  -91.14099631,  -13.15770391,\n",
       "         53.26155967])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"whrs\"] = df[\"whrs\"].apply(lambda x: max(x, 0))\n",
    "y = df[\"whrs\"]\n",
    "X = df[[\"kl6\", \"k618\", \"wa\", \"we\"]]\n",
    "X = sm.add_constant(X)\n",
    "df['cens'] = np.where(df['whrs'] == 0, 0, 0)\n",
    "cens = df['cens']\n",
    "tr = TobitModel()\n",
    "tr = tr.fit(X, y, cens, verbose=False)\n",
    "tr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_21004\\3479087987.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[y < 0] = 0  # Censuramos en 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (250,5) and (4,) not aligned: 5 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m X \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X)\n\u001b[0;32m     33\u001b[0m model \u001b[38;5;241m=\u001b[39m Tobit(y, X, left\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39msummary())\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:1015\u001b[0m, in \u001b[0;36mGenericLikelihoodModel.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, retall, **kwargs)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcov_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonrobust\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1014\u001b[0m fit_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit\n\u001b[1;32m-> 1015\u001b[0m mlefit \u001b[38;5;241m=\u001b[39m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1020\u001b[0m results_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults_class\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1021\u001b[0m                         GenericLikelihoodModelResults)\n\u001b[0;32m   1022\u001b[0m genericmlefit \u001b[38;5;241m=\u001b[39m results_class(\u001b[38;5;28mself\u001b[39m, mlefit)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:566\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_t\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    565\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Optimizer()\n\u001b[1;32m--> 566\u001b[0m xopt, retvals, optim_settings \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mhessian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;66;03m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[0;32m    576\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:243\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[1;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[0;32m    240\u001b[0m     fit_funcs\u001b[38;5;241m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[0;32m    242\u001b[0m func \u001b[38;5;241m=\u001b[39m fit_funcs[method]\n\u001b[1;32m--> 243\u001b[0m xopt, retvals \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m optim_settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: method, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_params\u001b[39m\u001b[38;5;124m'\u001b[39m: start_params,\n\u001b[0;32m    249\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_output\u001b[39m\u001b[38;5;124m'\u001b[39m: full_output,\n\u001b[0;32m    250\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfargs\u001b[39m\u001b[38;5;124m'\u001b[39m: fargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[0;32m    251\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretall\u001b[39m\u001b[38;5;124m'\u001b[39m: retall, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_fit_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m: extra_fit_funcs}\n\u001b[0;32m    252\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:737\u001b[0m, in \u001b[0;36m_fit_nm\u001b[1;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[0;32m    735\u001b[0m ftol \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mftol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m    736\u001b[0m maxfun \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxfun\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 737\u001b[0m retvals \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mftol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mftol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxfun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m retall:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:653\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(func, x0, args, xtol, ftol, maxiter, maxfun, full_output, disp, retall, callback, initial_simplex)\u001b[0m\n\u001b[0;32m    644\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxatol\u001b[39m\u001b[38;5;124m'\u001b[39m: xtol,\n\u001b[0;32m    645\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfatol\u001b[39m\u001b[38;5;124m'\u001b[39m: ftol,\n\u001b[0;32m    646\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_all\u001b[39m\u001b[38;5;124m'\u001b[39m: retall,\n\u001b[0;32m    650\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitial_simplex\u001b[39m\u001b[38;5;124m'\u001b[39m: initial_simplex}\n\u001b[0;32m    652\u001b[0m callback \u001b[38;5;241m=\u001b[39m _wrap_callback(callback)\n\u001b[1;32m--> 653\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_neldermead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[0;32m    655\u001b[0m     retlist \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfev\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:817\u001b[0m, in \u001b[0;36m_minimize_neldermead\u001b[1;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, bounds, **unknown_options)\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    816\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 817\u001b[0m         fsim[k] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _MaxFuncCallError:\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:526\u001b[0m, in \u001b[0;36m_wrap_scalar_function_maxfun_validation.<locals>.function_wrapper\u001b[1;34m(x, *wrapper_args)\u001b[0m\n\u001b[0;32m    524\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;66;03m# A copy of x is sent to the user function (gh13740)\u001b[39;00m\n\u001b[1;32m--> 526\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwrapper_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# Ideally, we'd like to a have a true scalar returned from f(x). For\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;66;03m# backwards-compatibility, also allow np.array([1.3]),\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;66;03m# np.array([[1.3]]) etc.\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:534\u001b[0m, in \u001b[0;36mLikelihoodModel.fit.<locals>.f\u001b[1;34m(params, *args)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(params, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nobs\n",
      "Cell \u001b[1;32mIn[23], line 16\u001b[0m, in \u001b[0;36mTobit.loglike\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m     13\u001b[0m sigma \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# La desviación estándar (último parámetro)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Predicciones lineales\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m xb \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Calcular la log-verosimilitud\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (250,5) and (4,) not aligned: 5 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "\n",
    "class Tobit(GenericLikelihoodModel):\n",
    "    def __init__(self, endog, exog, left=0, **kwds):\n",
    "        self.left = left\n",
    "        super().__init__(endog, exog, **kwds)\n",
    "\n",
    "    def loglike(self, params):\n",
    "        # Separar beta (coeficientes) y sigma (desviación estándar)\n",
    "        beta = params[:-1]  # Los coeficientes\n",
    "        sigma = params[-1]  # La desviación estándar (último parámetro)\n",
    "        \n",
    "        # Predicciones lineales\n",
    "        xb = np.dot(self.exog, beta)\n",
    "        y = self.endog\n",
    "\n",
    "        # Calcular la log-verosimilitud\n",
    "        ll = np.where(y > self.left,\n",
    "                      np.log(1 / sigma) + sm.distributions.norm.logpdf((y - xb) / sigma),\n",
    "                      sm.distributions.norm.logcdf((self.left - xb) / sigma))\n",
    "        \n",
    "        return ll.sum()\n",
    "\n",
    "# Cargar datos\n",
    "y = df[\"whrs\"]\n",
    "X = df[[\"kl6\", \"k618\", \"wa\", \"we\"]]\n",
    "y[y < 0] = 0  # Censuramos en 0\n",
    "\n",
    "# Ajustar modelo\n",
    "X = sm.add_constant(X)\n",
    "model = Tobit(y, X, left=0)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 5.468361\n",
      "         Iterations: 566\n",
      "         Function evaluations: 894\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Tobit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>                 <td>whrs</td>        <th>  Pseudo R-squ:      </th>   <td>0.008</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>Maximum Likelihood</td> <th>  Log-Likelihood:    </th>  <td>-1367.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>             <td>   250</td>       <th>  LL-Null:           </th>  <td>-1378.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Uncensored Obs:</th>             <td>150</td>        <th>  LL-Ratio:          </th>   <td>23.0</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Left-censored Obs:</th>          <td>100</td>        <th>  LLR p-value:       </th>   <td>0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Right-censored Obs:</th>          <td>0</td>         <th>  AIC:               </th>  <td>2744.2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>                 <td>   245</td>       <th>  BIC:               </th>  <td>2761.8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                     <td>     4</td>       <th>  Covariance Type:   </th> <td>nonrobust</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>      <td>  589.0003</td> <td>  841.589</td> <td>    0.700</td> <td> 0.484</td> <td>-1060.483</td> <td> 2238.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kl6</th>        <td> -827.7658</td> <td>  214.752</td> <td>   -3.855</td> <td> 0.000</td> <td>-1248.672</td> <td> -406.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>k618</th>       <td> -140.0192</td> <td>   74.227</td> <td>   -1.886</td> <td> 0.059</td> <td> -285.502</td> <td>    5.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wa</th>         <td>  -24.9792</td> <td>   13.257</td> <td>   -1.884</td> <td> 0.060</td> <td>  -50.963</td> <td>    1.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>we</th>         <td>  103.6896</td> <td>   41.826</td> <td>    2.479</td> <td> 0.013</td> <td>   21.712</td> <td>  185.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Log(Sigma)</th> <td>    7.1777</td> <td>    0.063</td> <td>  113.628</td> <td> 0.000</td> <td>    7.054</td> <td>    7.302</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}          &        whrs        & \\textbf{  Pseudo R-squ:      } &   0.008     \\\\\n",
       "\\textbf{Method:}                 & Maximum Likelihood & \\textbf{  Log-Likelihood:    } &  -1367.1    \\\\\n",
       "\\textbf{No. Observations:}       &          250       & \\textbf{  LL-Null:           } &  -1378.6    \\\\\n",
       "\\textbf{No. Uncensored Obs:}     &        150         & \\textbf{  LL-Ratio:          } &    23.0     \\\\\n",
       "\\textbf{No. Left-censored Obs:}  &        100         & \\textbf{  LLR p-value:       } &   0.000     \\\\\n",
       "\\textbf{No. Right-censored Obs:} &         0          & \\textbf{  AIC:               } &   2744.2    \\\\\n",
       "\\textbf{Df Residuals:}           &          245       & \\textbf{  BIC:               } &   2761.8    \\\\\n",
       "\\textbf{Df Model:}               &            4       & \\textbf{  Covariance Type:   } & nonrobust   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                    & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}      &     589.0003  &      841.589     &     0.700  &         0.484        &    -1060.483    &     2238.484     \\\\\n",
       "\\textbf{kl6}        &    -827.7658  &      214.752     &    -3.855  &         0.000        &    -1248.672    &     -406.860     \\\\\n",
       "\\textbf{k618}       &    -140.0192  &       74.227     &    -1.886  &         0.059        &     -285.502    &        5.463     \\\\\n",
       "\\textbf{wa}         &     -24.9792  &       13.257     &    -1.884  &         0.060        &      -50.963    &        1.004     \\\\\n",
       "\\textbf{we}         &     103.6896  &       41.826     &     2.479  &         0.013        &       21.712    &      185.668     \\\\\n",
       "\\textbf{Log(Sigma)} &       7.1777  &        0.063     &   113.628  &         0.000        &        7.054    &        7.302     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Tobit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                              Tobit Regression Results                             \n",
       "===================================================================================\n",
       "Dep. Variable:                        whrs   Pseudo R-squ:                    0.008\n",
       "Method:                 Maximum Likelihood   Log-Likelihood:                -1367.1\n",
       "No. Observations:                      250   LL-Null:                       -1378.6\n",
       "No. Uncensored Obs:                    150   LL-Ratio:                         23.0\n",
       "No. Left-censored Obs:                 100   LLR p-value:                     0.000\n",
       "No. Right-censored Obs:                  0   AIC:                            2744.2\n",
       "Df Residuals:                          245   BIC:                            2761.8\n",
       "Df Model:                                4   Covariance Type:             nonrobust\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        589.0003    841.589      0.700      0.484   -1060.483    2238.484\n",
       "kl6         -827.7658    214.752     -3.855      0.000   -1248.672    -406.860\n",
       "k618        -140.0192     74.227     -1.886      0.059    -285.502       5.463\n",
       "wa           -24.9792     13.257     -1.884      0.060     -50.963       1.004\n",
       "we           103.6896     41.826      2.479      0.013      21.712     185.668\n",
       "Log(Sigma)     7.1777      0.063    113.628      0.000       7.054       7.302\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from py4etrics.tobit import Tobit\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = df[\"whrs\"]\n",
    "x = df[[\"kl6\", \"k618\", \"wa\", \"we\"]]\n",
    "X = sm.add_constant(x)\n",
    "df['cens'] = np.where(df['whrs'] == 0, -1, 0)\n",
    "cens = df['cens']\n",
    "model = Tobit(y, X, cens).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 7.658411\n",
      "         Iterations: 4994\n",
      "         Function evaluations: 7886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:595: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Truncreg Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>whrs</td>        <th>  Pseudo R-squ:      </th>   <td>0.003</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Truncreg</td>      <th>  Log-Likelihood:    </th>  <td>-1914.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  LL-Null:           </th>  <td>-1921.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Sat, 22 Feb 2025</td>  <th>  LL-Ratio:          </th>   <td>13.0</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>23:35:32</td>      <th>  LLR p-value:       </th>   <td>0.011</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>   250</td>       <th>  AIC:               </th>  <td>3839.2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>   245</td>       <th>  BIC:               </th>  <td>3856.8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>     4</td>       <th>  Covariance Type:   </th> <td>nonrobust</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>      <td>-1.664e+10</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kl6</th>        <td>-5.197e+09</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>k618</th>       <td>-1.261e+08</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wa</th>         <td>-8.649e+07</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>we</th>         <td> 1.056e+08</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Log(Sigma)</th> <td>   15.1967</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        whrs        & \\textbf{  Pseudo R-squ:      } &   0.003     \\\\\n",
       "\\textbf{Model:}            &      Truncreg      & \\textbf{  Log-Likelihood:    } &  -1914.6    \\\\\n",
       "\\textbf{Method:}           & Maximum Likelihood & \\textbf{  LL-Null:           } &  -1921.1    \\\\\n",
       "\\textbf{Date:}             &  Sat, 22 Feb 2025  & \\textbf{  LL-Ratio:          } &    13.0     \\\\\n",
       "\\textbf{Time:}             &      23:35:32      & \\textbf{  LLR p-value:       } &   0.011     \\\\\n",
       "\\textbf{No. Observations:} &          250       & \\textbf{  AIC:               } &   3839.2    \\\\\n",
       "\\textbf{Df Residuals:}     &          245       & \\textbf{  BIC:               } &   3856.8    \\\\\n",
       "\\textbf{Df Model:}         &            4       & \\textbf{  Covariance Type:   } & nonrobust   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                    & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}      &   -1.664e+10  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{kl6}        &   -5.197e+09  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{k618}       &   -1.261e+08  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{wa}         &   -8.649e+07  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{we}         &    1.056e+08  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{Log(Sigma)} &      15.1967  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Truncreg Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                         Truncreg Regression Results                          \n",
       "==============================================================================\n",
       "Dep. Variable:                   whrs   Pseudo R-squ:                    0.003\n",
       "Model:                       Truncreg   Log-Likelihood:                -1914.6\n",
       "Method:            Maximum Likelihood   LL-Null:                       -1921.1\n",
       "Date:                Sat, 22 Feb 2025   LL-Ratio:                         13.0\n",
       "Time:                        23:35:32   LLR p-value:                     0.011\n",
       "No. Observations:                 250   AIC:                            3839.2\n",
       "Df Residuals:                     245   BIC:                            3856.8\n",
       "Df Model:                           4   Covariance Type:             nonrobust\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -1.664e+10        nan        nan        nan         nan         nan\n",
       "kl6        -5.197e+09        nan        nan        nan         nan         nan\n",
       "k618       -1.261e+08        nan        nan        nan         nan         nan\n",
       "wa         -8.649e+07        nan        nan        nan         nan         nan\n",
       "we          1.056e+08        nan        nan        nan         nan         nan\n",
       "Log(Sigma)    15.1967        nan        nan        nan         nan         nan\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from py4etrics.truncreg import Truncreg\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = df[\"whrs\"]\n",
    "x = df[[\"kl6\", \"k618\", \"wa\", \"we\"]]\n",
    "X = sm.add_constant(x)\n",
    "model = Truncreg(y, X, left=0).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import Bounds, minimize\n",
    "import re\n",
    "\n",
    "def truncreg(formula, data, point, direction, scaled=False, iterlim=50):\n",
    "    if direction not in [\"left\", \"right\"]:\n",
    "        raise ValueError(\"'direction' must be 'left' or 'right'\")\n",
    "    \n",
    "    x_vars = re.split(r'[*+]', re.search(r'~\\s*(.+)', formula).group(1).strip())\n",
    "    x_vars = [var.strip() for var in x_vars]\n",
    "    x = data[[var for var in x_vars if var]]\n",
    "    y = data[formula.split('~')[0].strip()]\n",
    "    \n",
    "    intercept = np.ones((x.shape[0], 1))\n",
    "    x = np.hstack((intercept, x))\n",
    "    \n",
    "    if direction == \"left\" and any(y < point):\n",
    "        raise ValueError(\"Data non-truncated, contains observations < '{}'\".format(point))\n",
    "    if direction == \"right\" and any(y > point):\n",
    "        raise ValueError(\"Data non-truncated, contains observations > '{}'\".format(point))\n",
    "\n",
    "    def maxLikTruncreg(param, x, y, point, direction, scaled=scaled):\n",
    "        epsilon = 1e-8\n",
    "        sign = 1 if direction == \"left\" else -1\n",
    "        beta = param[:-1]\n",
    "        sigma = param[-1]\n",
    "        bX = np.dot(x, beta)\n",
    "        \n",
    "        if not scaled:\n",
    "            resid = y - bX\n",
    "            trunc = bX - point\n",
    "    \n",
    "            #Potential Overflow Handling\n",
    "            exp_argument = norm.logpdf(sign * trunc / (sigma + epsilon)) - norm.logcdf(sign * trunc / (sigma + epsilon))\n",
    "            exp_argument = np.clip(exp_argument, a_min=None, a_max=700)\n",
    "            mills = np.exp(exp_argument)\n",
    "    \n",
    "            lnL = -np.log(sigma + epsilon) + norm.logpdf(resid / (sigma + epsilon)) - norm.logcdf(sign * trunc / (sigma + epsilon))\n",
    "            logLik = lnL.sum() if isinstance(lnL, np.ndarray) and lnL.ndim > 0 else lnL\n",
    "    \n",
    "            # Gradient calculation\n",
    "            gbX = resid / (sigma ** 2 + epsilon) - sign * mills / (sigma + epsilon)\n",
    "            gsigma = -1 / (sigma + epsilon) + resid ** 2 / (sigma + epsilon) ** 3 + sign * mills * trunc / (sigma + epsilon) ** 2\n",
    "            gradient = np.concatenate([gbX, gsigma])\n",
    "    \n",
    "            # Hessian calculation\n",
    "            bb = -1 / (sigma ** 2 + epsilon) + mills * (sign * trunc / (sigma + epsilon) + mills) / (sigma + epsilon) ** 2\n",
    "            ss = 1 / (sigma + epsilon) ** 2 - 3 * resid ** 2 / (sigma + epsilon) ** 4 - 2 * mills * sign * trunc / (sigma + epsilon) ** 3 + \\\n",
    "                 mills * (sign * trunc / (sigma + epsilon) + mills) * trunc ** 2 / (sigma + epsilon) ** 4\n",
    "            bs = -2 * resid / (sigma + epsilon) ** 3 + sign * mills / (sigma + epsilon) ** 2 - \\\n",
    "                 mills * (mills + sign * trunc / (sigma + epsilon)) * trunc / (sigma + epsilon) ** 3\n",
    "            bs = np.array(bs)\n",
    "    \n",
    "            bb_matrix = np.dot(x.T, np.reshape(bb, (-1, 1)) * x)\n",
    "            bs_vector = np.sum(np.reshape(bs, (-1, 1)) * x, axis=0)\n",
    "            bs_vector = np.reshape(bs_vector, (-1, 1))\n",
    "            ss_scalar = np.array([[np.sum(ss)]])\n",
    "    \n",
    "            hessian = np.block([[bb_matrix, bs_vector],\n",
    "                            [bs_vector.T, ss_scalar]])\n",
    "        else:\n",
    "            exp_argument = norm.logpdf(sign * (bX - point / (sigma + epsilon))) - norm.logcdf(sign * (bX - point / (sigma + epsilon)))\n",
    "            exp_argument = np.clip(exp_argument, a_min=None, a_max=700)\n",
    "            mills = np.exp(exp_argument)\n",
    "            \n",
    "            lnL = -np.log(sigma + epsilon) + norm.logpdf(y / (sigma + epsilon) - bX) - norm.logcdf(sign * (bX - point / (sigma + epsilon)))\n",
    "            logLik = lnL.sum() if isinstance(lnL, np.ndarray) and lnL.ndim > 0 else lnL\n",
    "            \n",
    "            #Gradient calculation\n",
    "            gbX = (y / sigma - bX + epsilon) - mills * sign\n",
    "            gsigma = -1 / (sigma + epsilon) + (y / sigma + epsilon - bX) * y /(sigma + epsilon) ** 2 - sign * mills * point/(sigma + epsilon) ** 2\n",
    "            gradient = np.concatenate([gbX, gsigma])\n",
    "            \n",
    "            #Hessian Calculation\n",
    "            bb = -1 + mills * (mills + sign * (bX - point / (sigma + epsilon)))\n",
    "            bs = -y / sigma ** 2 + (mills + sign * (bX - point / (sigma + epsilon))) * mills * point / (sigma + epsilon) ** 2\n",
    "            ss = 1 / (sigma + epsilon) ** 2 - 3 * y ** 2 / (sigma + epsilon) ** 4 + 2 * bX * y / (sigma + epsilon) ** 3 + \\\n",
    "                mills * (mills + sign * (bX - point / (sigma + epsilon))) * point ** 2 / (sigma + epsilon) ** 4 + \\\n",
    "                2 * sign * mills * point / (sigma + epsilon) ** 3\n",
    "            bs = np.array(bs)\n",
    "            \n",
    "            bb_matrix = np.dot(x.T, np.reshape(bb, (-1, 1)) * x)\n",
    "            bs_vector = np.sum(np.reshape(bs, (-1, 1)) * x, axis=0)\n",
    "            bs_vector = np.reshape(bs_vector, (-1, 1))\n",
    "            ss_scalar = np.array([[np.sum(ss)]])\n",
    "            \n",
    "            hessian = np.block([[bb_matrix, bs_vector],\n",
    "                            [bs_vector.T, ss_scalar]])\n",
    "            \n",
    "        return {\n",
    "            'logLik': logLik, \n",
    "            'gradient': gradient, \n",
    "            'hessian': hessian\n",
    "        }\n",
    "\n",
    "    def objective(param):\n",
    "        result = maxLikTruncreg(param, x, y, point, direction)\n",
    "        return -result['logLik']\n",
    "\n",
    "    linmod = np.linalg.lstsq(x, y, rcond=None)\n",
    "    start_beta = linmod[0]\n",
    "    start_sigma = np.array([np.std(linmod[1])])\n",
    "    start = np.concatenate([start_beta, start_sigma])\n",
    "\n",
    "    lower_bounds = [np.NINF] * (len(start) - 1) + [1e-4]\n",
    "    upper_bounds = [np.inf] * len(start)\n",
    "    bounds = Bounds(lower_bounds, upper_bounds)\n",
    "\n",
    "    result = minimize(objective, start, method='L-BFGS-B', bounds=bounds, options={'maxiter': iterlim})\n",
    "    opt_result = maxLikTruncreg(result.x, x, y, point, direction, scaled)\n",
    "    vcov = -np.linalg.inv(opt_result['hessian'])\n",
    "    std_errors = np.sqrt(np.diag(vcov))\n",
    "    \n",
    "    return {\n",
    "        'result': result,\n",
    "        'vcov': vcov,\n",
    "        'SE': std_errors\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result':   message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "  success: False\n",
      "   status: 1\n",
      "      fun: 2108.38559242432\n",
      "        x: [ 9.393e+02 -4.677e+02 -9.946e+01 -1.575e+01  5.119e+01\n",
      "             5.322e+02]\n",
      "      nit: 50\n",
      "      jac: [-1.723e-02  3.402e-02  2.765e-02 -1.001e+00 -2.767e-01\n",
      "            -9.420e-01]\n",
      "     nfev: 455\n",
      "     njev: 65\n",
      " hess_inv: <6x6 LbfgsInvHessProduct with dtype=float64>, 'vcov': array([[ 1.43858120e+05, -1.25420225e+04, -6.10188647e+03,\n",
      "        -1.73430874e+03, -4.60015031e+03, -1.07771422e+02],\n",
      "       [-1.25420225e+04,  1.14460624e+04,  4.09661983e+02,\n",
      "         2.69847936e+02, -1.29942821e+02,  1.01826624e+02],\n",
      "       [-6.10188647e+03,  4.09661983e+02,  1.26477413e+03,\n",
      "         9.35012849e+01,  3.27066443e+01,  5.75536589e+00],\n",
      "       [-1.73430874e+03,  2.69847936e+02,  9.35012849e+01,\n",
      "         3.54375023e+01,  3.49471335e+00, -6.66373172e-01],\n",
      "       [-4.60015031e+03, -1.29942821e+02,  3.27066443e+01,\n",
      "         3.49471335e+00,  3.54336606e+02, -3.29834148e+00],\n",
      "       [-1.07771422e+02,  1.01826624e+02,  5.75536589e+00,\n",
      "        -6.66373172e-01, -3.29834148e+00,  1.67655274e+02]]), 'SE': array([379.28632962, 106.98627213,  35.56366307,   5.95294065,\n",
      "        18.82383081,  12.94817648])}\n"
     ]
    }
   ],
   "source": [
    "result = truncreg(formula='whrs~kl6+k618+wa+we', data=df, point=0, direction='left')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result':   message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
       "   success: False\n",
       "    status: 1\n",
       "       fun: 2108.38559242432\n",
       "         x: [ 9.393e+02 -4.677e+02 -9.946e+01 -1.575e+01  5.119e+01\n",
       "              5.322e+02]\n",
       "       nit: 50\n",
       "       jac: [-1.723e-02  3.402e-02  2.765e-02 -1.001e+00 -2.767e-01\n",
       "             -9.420e-01]\n",
       "      nfev: 455\n",
       "      njev: 65\n",
       "  hess_inv: <6x6 LbfgsInvHessProduct with dtype=float64>,\n",
       " 'vcov': array([[ 1.43858120e+05, -1.25420225e+04, -6.10188647e+03,\n",
       "         -1.73430874e+03, -4.60015031e+03, -1.07771422e+02],\n",
       "        [-1.25420225e+04,  1.14460624e+04,  4.09661983e+02,\n",
       "          2.69847936e+02, -1.29942821e+02,  1.01826624e+02],\n",
       "        [-6.10188647e+03,  4.09661983e+02,  1.26477413e+03,\n",
       "          9.35012849e+01,  3.27066443e+01,  5.75536589e+00],\n",
       "        [-1.73430874e+03,  2.69847936e+02,  9.35012849e+01,\n",
       "          3.54375023e+01,  3.49471335e+00, -6.66373172e-01],\n",
       "        [-4.60015031e+03, -1.29942821e+02,  3.27066443e+01,\n",
       "          3.49471335e+00,  3.54336606e+02, -3.29834148e+00],\n",
       "        [-1.07771422e+02,  1.01826624e+02,  5.75536589e+00,\n",
       "         -6.66373172e-01, -3.29834148e+00,  1.67655274e+02]]),\n",
       " 'SE': array([379.28632962, 106.98627213,  35.56366307,   5.95294065,\n",
       "         18.82383081,  12.94817648])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

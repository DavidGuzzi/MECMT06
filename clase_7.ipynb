{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadstat as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lfp</th>\n",
       "      <th>whrs</th>\n",
       "      <th>kl6</th>\n",
       "      <th>k618</th>\n",
       "      <th>wa</th>\n",
       "      <th>we</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1610</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1568</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lfp  whrs  kl6  k618  wa  we\n",
       "0    1  1610    1     0  32  12\n",
       "1    1  1656    0     2  30  12\n",
       "2    1  1980    1     3  35  12\n",
       "3    1   456    0     3  34  12\n",
       "4    1  1568    1     2  31  14"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\DiTella\\MEC\\Materias\\2024 3T\\[MT06] Microeconometría I\\Clases\\Stata\\Archivos Stata-20250107\\laborsub.dta\"\n",
    "\n",
    "df, meta = st.read_dta(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   lfp     250 non-null    int64\n",
      " 1   whrs    250 non-null    int64\n",
      " 2   kl6     250 non-null    int64\n",
      " 3   k618    250 non-null    int64\n",
      " 4   wa      250 non-null    int64\n",
      " 5   we      250 non-null    int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 11.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 if woman worked in 1975',\n",
       " \"Wife's hours of work\",\n",
       " '# of children younger than 6',\n",
       " '# of children between 6 and 18',\n",
       " \"Wife's age\",\n",
       " \"Wife's educational attainment\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.column_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lfp\n",
       "1    150\n",
       "0    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lfp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>whrs</th>\n",
       "      <td>250.0</td>\n",
       "      <td>799.84</td>\n",
       "      <td>915.60348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.5</td>\n",
       "      <td>1599.75</td>\n",
       "      <td>4950.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count    mean        std  min  25%    50%      75%     max\n",
       "whrs  250.0  799.84  915.60348  0.0  0.0  406.5  1599.75  4950.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['whrs']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   whrs   R-squared:                       0.072\n",
      "Model:                            OLS   Adj. R-squared:                  0.046\n",
      "Method:                 Least Squares   F-statistic:                     2.802\n",
      "Date:                Thu, 20 Feb 2025   Prob (F-statistic):             0.0281\n",
      "Time:                        23:26:34   Log-Likelihood:                -1214.6\n",
      "No. Observations:                 150   AIC:                             2439.\n",
      "Df Residuals:                     145   BIC:                             2454.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1629.8168    615.130      2.650      0.009     414.037    2845.597\n",
      "kl6         -421.4822    167.973     -2.509      0.013    -753.475     -89.490\n",
      "k618        -104.4571     54.186     -1.928      0.056    -211.554       2.640\n",
      "wa            -4.7849      9.691     -0.494      0.622     -23.938      14.368\n",
      "we             9.3532     31.238      0.299      0.765     -52.387      71.094\n",
      "==============================================================================\n",
      "Omnibus:                       28.314   Durbin-Watson:                   2.066\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               53.578\n",
      "Skew:                           0.864   Prob(JB):                     2.32e-12\n",
      "Kurtosis:                       5.364   Cond. No.                         425.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#¿Qué sucede si queremos estimar una función de oferta de trabajo?\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Filtrar datos donde whrs > 0\n",
    "df_filtered = df[df[\"whrs\"] > 0]\n",
    "\n",
    "# Definir variables dependiente (Y) e independientes (X)\n",
    "y = df_filtered[\"whrs\"]\n",
    "X = df_filtered[[\"kl6\", \"k618\", \"wa\", \"we\"]]\n",
    "\n",
    "# Agregar constante para la intersección (equivalente a _cons en Stata)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Ajustar el modelo\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Mostrar resultados\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Tobit' from 'statsmodels.discrete.count_model' (c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\discrete\\count_model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiscrete\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcount_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tobit\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Definir variables dependiente (Y) e independientes (X)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhrs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Tobit' from 'statsmodels.discrete.count_model' (c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\discrete\\count_model.py)"
     ]
    }
   ],
   "source": [
    "from statsmodels.discrete.count_model import Tobit\n",
    "\n",
    "# Definir variables dependiente (Y) e independientes (X)\n",
    "y = df[\"whrs\"]\n",
    "X = df[[\"kl6\", \"k618\", \"wa\", \"we\"]]\n",
    "\n",
    "# Agregar constante para la intersección (equivalente a _cons en Stata)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Ajustar el modelo Tobit con censura inferior en 0\n",
    "model = Tobit(y, X).fit(censor_lower=0)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:592: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x1) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes estimados: [-5200401.23618509  1717029.03177521   313985.12206049    94771.03642374\n",
      "    44524.92114298]\n",
      "Sigma estimado: 510055.98735519126\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Definir variables dependiente (Y) e independientes (X)\n",
    "y = df[\"whrs\"]\n",
    "X = df[[\"kl6\", \"k618\", \"wa\", \"we\"]]\n",
    "\n",
    "# Agregar constante\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Función de log-verosimilitud del modelo Tobit (censura inferior en 0)\n",
    "def tobit_loglik(params, y, X):\n",
    "    beta = params[:-1]  # Coeficientes de regresión\n",
    "    sigma = params[-1]  # Desviación estándar del error\n",
    "    \n",
    "    if sigma <= 0:\n",
    "        return np.inf  # Evitar valores no válidos\n",
    "    \n",
    "    xb = X @ beta  # Producto matricial X * beta\n",
    "    uncensored = (y > 0)\n",
    "    \n",
    "    # Parte no censurada: Log-verosimilitud de la normal\n",
    "    ll_uncensored = -0.5 * np.log(2 * np.pi) - np.log(sigma) - (y - xb) ** 2 / (2 * sigma**2)\n",
    "    \n",
    "    # Parte censurada: Probabilidad acumulada de la normal (usando scipy.stats.norm)\n",
    "    ll_censored = np.log(np.maximum(norm.cdf(xb / sigma), 1e-10))  # Evita log(0)\n",
    "    \n",
    "    # Combinar log-verosimilitudes\n",
    "    loglik = np.where(uncensored, ll_uncensored, ll_censored)\n",
    "    \n",
    "    return -np.sum(loglik)  # Maximizar la verosimilitud minimizando la función de pérdida\n",
    "\n",
    "# Estimación de parámetros iniciales\n",
    "init_params = np.append(np.zeros(X.shape[1]), 1)  # Coeficientes iniciales + sigma\n",
    "\n",
    "# Optimización numérica\n",
    "res = minimize(tobit_loglik, init_params, args=(y, X), method=\"BFGS\")\n",
    "\n",
    "# Resultados\n",
    "beta_est = res.x[:-1]  # Coeficientes estimados\n",
    "sigma_est = res.x[-1]  # Estimación de sigma\n",
    "\n",
    "print(\"Coeficientes estimados:\", beta_est)\n",
    "print(\"Sigma estimado:\", sigma_est)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats\n",
    "from scipy.special import log_ndtr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def split_left_right_censored(x, y, cens):\n",
    "    counts = cens.value_counts()\n",
    "    if -1 not in counts and 1 not in counts:\n",
    "        warnings.warn(\"No censored observations; use regression methods for uncensored data\")\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for value in [-1, 0, 1]:\n",
    "        if value in counts:\n",
    "            split = cens == value\n",
    "            y_split = np.squeeze(y[split].values)\n",
    "            x_split = x[split].values\n",
    "\n",
    "        else:\n",
    "            y_split, x_split = None, None\n",
    "        xs.append(x_split)\n",
    "        ys.append(y_split)\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "def tobit_neg_log_likelihood(xs, ys, params):\n",
    "    x_left, x_mid, x_right = xs\n",
    "    y_left, y_mid, y_right = ys\n",
    "\n",
    "    b = params[:-1]\n",
    "    # s = math.exp(params[-1])\n",
    "    s = params[-1]\n",
    "\n",
    "    to_cat = []\n",
    "\n",
    "    cens = False\n",
    "    if y_left is not None:\n",
    "        cens = True\n",
    "        left = (y_left - np.dot(x_left, b))\n",
    "        to_cat.append(left)\n",
    "    if y_right is not None:\n",
    "        cens = True\n",
    "        right = (np.dot(x_right, b) - y_right)\n",
    "        to_cat.append(right)\n",
    "    if cens:\n",
    "        concat_stats = np.concatenate(to_cat, axis=0) / s\n",
    "        log_cum_norm = scipy.stats.norm.logcdf(concat_stats)  # log_ndtr(concat_stats)\n",
    "        cens_sum = log_cum_norm.sum()\n",
    "    else:\n",
    "        cens_sum = 0\n",
    "\n",
    "    if y_mid is not None:\n",
    "        mid_stats = (y_mid - np.dot(x_mid, b)) / s\n",
    "        mid = scipy.stats.norm.logpdf(mid_stats) - math.log(max(np.finfo('float').resolution, s))\n",
    "        mid_sum = mid.sum()\n",
    "    else:\n",
    "        mid_sum = 0\n",
    "\n",
    "    loglik = cens_sum + mid_sum\n",
    "\n",
    "    return - loglik\n",
    "\n",
    "\n",
    "def tobit_neg_log_likelihood_der(xs, ys, params):\n",
    "    x_left, x_mid, x_right = xs\n",
    "    y_left, y_mid, y_right = ys\n",
    "\n",
    "    b = params[:-1]\n",
    "    # s = math.exp(params[-1]) # in censReg, not using chain rule as below; they optimize in terms of log(s)\n",
    "    s = params[-1]\n",
    "\n",
    "    beta_jac = np.zeros(len(b))\n",
    "    sigma_jac = 0\n",
    "\n",
    "    if y_left is not None:\n",
    "        left_stats = (y_left - np.dot(x_left, b)) / s\n",
    "        l_pdf = scipy.stats.norm.logpdf(left_stats)\n",
    "        l_cdf = log_ndtr(left_stats)\n",
    "        left_frac = np.exp(l_pdf - l_cdf)\n",
    "        beta_left = np.dot(left_frac, x_left / s)\n",
    "        beta_jac -= beta_left\n",
    "\n",
    "        left_sigma = np.dot(left_frac, left_stats)\n",
    "        sigma_jac -= left_sigma\n",
    "\n",
    "    if y_right is not None:\n",
    "        right_stats = (np.dot(x_right, b) - y_right) / s\n",
    "        r_pdf = scipy.stats.norm.logpdf(right_stats)\n",
    "        r_cdf = log_ndtr(right_stats)\n",
    "        right_frac = np.exp(r_pdf - r_cdf)\n",
    "        beta_right = np.dot(right_frac, x_right / s)\n",
    "        beta_jac += beta_right\n",
    "\n",
    "        right_sigma = np.dot(right_frac, right_stats)\n",
    "        sigma_jac -= right_sigma\n",
    "\n",
    "    if y_mid is not None:\n",
    "        mid_stats = (y_mid - np.dot(x_mid, b)) / s\n",
    "        beta_mid = np.dot(mid_stats, x_mid / s)\n",
    "        beta_jac += beta_mid\n",
    "\n",
    "        mid_sigma = (np.square(mid_stats) - 1).sum()\n",
    "        sigma_jac += mid_sigma\n",
    "\n",
    "    combo_jac = np.append(beta_jac, sigma_jac / s)  # by chain rule, since the expression above is dloglik/dlogsigma\n",
    "\n",
    "    return -combo_jac\n",
    "\n",
    "\n",
    "class TobitModel:\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.ols_coef_ = None\n",
    "        self.ols_intercept = None\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.sigma_ = None\n",
    "\n",
    "    def fit(self, x, y, cens, verbose=False):\n",
    "        \"\"\"\n",
    "        Fit a maximum-likelihood Tobit regression\n",
    "        :param x: Pandas DataFrame (n_samples, n_features): Data\n",
    "        :param y: Pandas Series (n_samples,): Target\n",
    "        :param cens: Pandas Series (n_samples,): -1 indicates left-censored samples, 0 for uncensored, 1 for right-censored\n",
    "        :param verbose: boolean, show info from minimization\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x_copy = x.copy()\n",
    "        if self.fit_intercept:\n",
    "            x_copy.insert(0, 'intercept', 1.0)\n",
    "        else:\n",
    "            x_copy.scale(with_mean=True, with_std=False, copy=False)\n",
    "        init_reg = LinearRegression(fit_intercept=False).fit(x_copy, y)\n",
    "        b0 = init_reg.coef_\n",
    "        y_pred = init_reg.predict(x_copy)\n",
    "        resid = y - y_pred\n",
    "        resid_var = np.var(resid)\n",
    "        s0 = np.sqrt(resid_var)\n",
    "        params0 = np.append(b0, s0)\n",
    "        xs, ys = split_left_right_censored(x_copy, y, cens)\n",
    "\n",
    "        result = minimize(lambda params: tobit_neg_log_likelihood(xs, ys, params), params0, method='BFGS',\n",
    "                          jac=lambda params: tobit_neg_log_likelihood_der(xs, ys, params), options={'disp': verbose})\n",
    "        if verbose:\n",
    "            print(result)\n",
    "        self.ols_coef_ = b0[1:]\n",
    "        self.ols_intercept = b0[0]\n",
    "        if self.fit_intercept:\n",
    "            self.intercept_ = result.x[1]\n",
    "            self.coef_ = result.x[1:-1]\n",
    "        else:\n",
    "            self.coef_ = result.x[:-1]\n",
    "            self.intercept_ = 0\n",
    "        self.sigma_ = result.x[-1]\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.intercept_ + np.dot(x, self.coef_)\n",
    "\n",
    "    def score(self, x, y, scoring_function=mean_absolute_error):\n",
    "        y_pred = np.dot(x, self.coef_)\n",
    "        return scoring_function(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 294.44827939, -827.78090417, -140.01430074,  -24.97854148,\n",
       "        103.69518044])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"whrs\"]\n",
    "X = df[[\"kl6\", \"k618\", \"wa\", \"we\"]]\n",
    "X = sm.add_constant(X)\n",
    "df['cens'] = np.where(df['whrs'] == 0, -1, 0)\n",
    "cens = df['cens']\n",
    "tr = TobitModel()\n",
    "tr = tr.fit(X, y, cens, verbose=False)\n",
    "tr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
